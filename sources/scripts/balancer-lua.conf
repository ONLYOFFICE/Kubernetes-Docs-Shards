access_by_lua_block {
 local WOPISrc = ngx.var.arg_WOPISrc
 local shardkey = ngx.var.arg_shardkey
 local service_name = ngx.var.service_name
 {{- if and (eq .Values.connections.redisConnectorName "redis") (not .Values.connections.redisClusterNodes) }}
 local redis = require "resty.redis"
 local red = redis:new()
 {{- end }}
 {{- if eq .Values.connections.redisConnectorName "ioredis" }}
 local red
 {{- end }}
 local cjson = require("cjson.safe")
 local configuration = require("configuration")
 local docs_balancer = require("docs_balancer")
 local request_uri = ngx.var.request_uri
 local requested_version = request_uri:match("/([%d%.%-]+%-[^/]+)/")
 local service_port = {{ .Values.documentserver.proxy.containerPorts.http }}

 {{- if .Values.connections.redisClusterNodes }}
 local config = {
      dict_name = "redis_cluster_slot_locks",
      name = "clusterRedis",
      serv_list = {
         {{- range $node := .Values.connections.redisClusterNodes }}
           {{- $parts := splitList ":" $node }}
           { ip = "{{ index $parts 0 }}", port = {{ index $parts 1 }} },
         {{- end }}
      },
      keepalive_timeout = 60000,
      keepalive_cons = 1000000,
      connect_timeout = 1000,
      max_redirection = 5,
      max_connection_attempts = 1,
      {{- if eq .Values.connections.redisNoPass false }}
      auth = {{ include "ds.redis.pass" . | quote }},
      {{- end }}
  }
  local redis = require "resty.redis.rediscluster"
  local red = redis:new(config)
 {{- end }}

 local function redis_del(key)
   local ok, err = red:del(string.format("%s", key))
   if not ok then
     ngx.say("failed to del: ", err)
     return
   end
 end

 local function redis_get(wopi)
   local user_data_response = red:get(string.format('%s', wopi))
   return user_data_response
 end

 local function redis_set(wopi, endpoint)
   local response = red:setnx(string.format('%s', wopi), endpoint)
   if response == 1 then
     {{- if eq .Values.customBalancer.log.level "DEBUG" }}
     print(string.format("DEBUG: New api key %s was set in Redis", wopi))
     {{- end }}
     return true
   end
 end

 local function redis_set_ipkey(wopi, endpoint)
   local wopi_final = (string.format(" %s", wopi))
   local ok, err = red:append(string.format('%s', endpoint), wopi_final)
   if not ok then
     ngx.say("failed to set: ",err)
     return
   end
 end

 local function get_endpoints(backends, upstream)
   for _, new_backend in ipairs(backends) do
       if new_backend.name == upstream then
          local new_endpoints=(new_backend.endpoints)
          return new_endpoints
       end
   end
 end

 local function table_contains(tbl, p, x)
   local found = false
   for _, v in pairs(tbl) do
       local endpoint_string = (string.format("%s:%s", v, p))
       if endpoint_string == x then
          local found = true
          return found
       end
   end
   return found
 end

 local function check_endpoint(t, endpoint)
   local docs_upstream = ngx.var.proxy_upstream_name
   local backends_data
   local timeout = 0

   if t == "reserved" then
     repeat
        backends_data = configuration.get_reserved_data()
        {{- if eq .Values.customBalancer.log.level "DEBUG" }}
        print(string.format("DEBUG: CHECK ENDPOINT:%s IN RESERVED", endpoint))
        {{- end }}
        local decoded_table = cjson.decode(backends_data)
        if decoded_table == nil then
            return "empty"
        end
        local address = decoded_table[1].address
        if address == "none" then
            ngx.sleep(1)
            timeout = timeout + 1
            print("No active shards found, waiting...")
        else
            break
        end
     until timeout >= 5
   end

   if t == "reserved" and timeout >= 5 then
     {{- if eq .Values.customBalancer.log.level "DEBUG" }}
     print("DEBUG: Balancer table return empty, set new address")
     {{- end }}
     return "empty"
   end

   if t == "live" then
     {{- if eq .Values.customBalancer.log.level "DEBUG" }}
     print(string.format("DEBUG: CHECK ENDPOINT:%s IN LIVE", endpoint))
     {{- end }}
     backends_data = configuration.get_backends_data()
   end

   local backends = cjson.decode(backends_data)
   local endpoints = backends
   local endpoints_table = {}
   for _, endpoint in ipairs(endpoints) do
       table.insert(endpoints_table, endpoint.address)
   end
   local result = table_contains(endpoints_table, service_port, endpoint)
   return result
 end

 local function get_docs_mode(wopi)
   if string.match(wopi, "http://") or string.match(wopi, "https://") then
     return "wopi"
   else
     return "api"
   end
 end

 local function get_api_arg()
   if WOPISrc then
     return WOPISrc
   end
   if shardkey then
     return shardkey
   end
 end

 local function handle_api_key(arg)
   if shardkey then
      return shardkey
   end
   if WOPISrc then
      local WOPIDecoded = (ngx.unescape_uri(arg))
      local WOPIkey = WOPIDecoded:gsub("%s+", "")
      return WOPIkey
   end
 end

 {{- if and (eq .Values.connections.redisConnectorName "redis") (not .Values.connections.redisClusterNodes) }}
 local function init_redis_connection()
   red:set_timeouts(1000, 1000, 1000) -- 1 sec
   local ok, err = red:connect({{ .Values.connections.redisHost | quote }}, {{ .Values.connections.redisPort }})
   if not ok then
        ngx.say("1: failed to connect: ",err)
        return
   end

   {{- if eq .Values.connections.redisNoPass false }}
   local res, err = red:auth({{ .Values.connections.redisUser | quote }}, {{ include "ds.redis.pass" . | quote }})
   if not res then
       ngx.say("failed to authenticate: ", err)
       return
   end
   {{- end }}
 end
 {{- end }}

 {{- if eq .Values.connections.redisConnectorName "ioredis" }}
 local function init_redis_connection()
  local rc = require("resty.redis.connector").new()
  local sentinel, err = rc:connect({
   url = "sentinel://{{ .Values.connections.redisSentinelGroupName }}:m/{{ .Values.documentserver.keysRedisDBNum }}",
   {{- if .Values.connections.redisSentinelUser }}
   sentinel_username = {{ .Values.connections.redisSentinelUser | quote }},
   {{- end }}
   {{- if eq .Values.connections.redisSentinelNoPass false }}
   sentinel_password = {{ include "ds.redis.sentinel.pass" . | quote }},
   {{- end }}
   {{- if .Values.connections.redisUser }}
   username = {{ .Values.connections.redisUser | quote }},
   {{- end }}
   {{- if eq .Values.connections.redisNoPass false }}
   password = {{ include "ds.redis.pass" . | quote }},
   {{- end }}
   sentinels = {
      {{- if .Values.connections.redisSentinelNodes }}
        {{- range $index, $hostport := .Values.connections.redisSentinelNodes }}
        {{- $parts := splitList ":" $hostport }}
        { host = "{{ index $parts 0 }}", port = {{ index $parts 1 }} }{{ if ne (add $index 1) (len $.Values.connections.redisSentinelNodes) }},{{ end }}
        {{- end }}
      {{- else }}
        { host = "{{ .Values.connections.redisHost }}", port = {{ .Values.connections.redisPort }} }
      {{- end }}
   }
  })
  red = sentinel
 end
 {{- end }}

 local function api_js_exist()
  if string.match(request_uri, "api%.js$") then
    return true
  else
    return false
  end
 end

 local function set_custom_endpoint(shardkey)
    local new_custom_endpoint = docs_balancer.balance_ep()
    if redis_set(shardkey, new_custom_endpoint) then
      redis_set_ipkey(shardkey, new_custom_endpoint)
      ngx.var.custom_endpoint = new_custom_endpoint
      {{- if eq .Values.customBalancer.log.level "DEBUG" }}
      print(string.format("DEBUG: Set endpoint: %s for shardkey: %s", new_custom_endpoint, shardkey))
      {{- end }}
    else
      {{- if eq .Values.customBalancer.log.level "DEBUG" }}
      print("DEBUG: Looks like parallel request was made, get endpoint from Redis")
      {{- end }}
      ngx.var.custom_endpoint = tostring(redis_get(shardkey))
    end
 end

 -- This function is used only for reset shardkey with issues
 -- (endpoint is not exist anymore in any table for example)
 local function reset_custom_endpoint(shardkey)
   {{- if eq .Values.customBalancer.log.level "DEBUG" }}
   print(string.format("DEBUG: Call reset for shardkey: %s", shardkey))
   {{- end }}
   local new_custom_endpoint = docs_balancer.balance_ep()
   local script = [[
     if redis.call('SET', KEYS[2], 1, 'NX', 'PX', 5000) then
        redis.call('DEL', KEYS[1])
        redis.call('SET', KEYS[1], ARGV[1])
        return 1
     end
     return 0
   ]]

   shardkey_lock = shardkey .. ":lock"

   local result, err = red:eval(script, 2,
                         shardkey,
                         shardkey_lock,
                         new_custom_endpoint)

   if result == '1' then
           {{- if eq .Values.customBalancer.log.level "DEBUG" }}
           print(string.format("DEBUG: New endpoint %s was re-set for %s", new_custom_endpoint, shardkey))
           {{- end }}
           ngx.var.custom_endpoint = new_custom_endpoint
   elseif result == '0' then
           {{- if eq .Values.customBalancer.log.level "DEBUG" }}
           print("DEBUG: Parallell re-set function call, get value from redis")
           {{- end }}
           ngx.var.custom_endpoint = tostring(redis_get(shardkey))
   end
 end

 local API_ARG = get_api_arg()

 if API_ARG and string.len(API_ARG) > 0 then
 local API_KEY = handle_api_key(API_ARG)

 {{- if not .Values.connections.redisClusterNodes }}
 init_redis_connection()
 {{- end }}

 {{- if and (ne .Values.documentserver.keysRedisDBNum "0") (eq .Values.connections.redisConnectorName "redis") (not .Values.connections.redisClusterNodes) }}
 red:select({{ .Values.documentserver.keysRedisDBNum }})
 {{- end }}

 local exist_endpoint = tostring(redis_get(API_KEY))
 if exist_endpoint == 'userdata: NULL' then
      set_custom_endpoint(API_KEY)
 else
   {{- if eq .Values.customBalancer.log.level "DEBUG" }}
   print(string.format("DEBUG: ENDPOINT %s exist in Redis, check in balancer tables...", exist_endpoint))
   {{- end }}
   local endpoint_found_live = check_endpoint("live", exist_endpoint)
   if endpoint_found_live == false then
     local endpoint_found_reserved = check_endpoint("reserved", exist_endpoint)
     if endpoint_found_reserved == false or endpoint_found_reserved == "empty" then
       {{- if eq .Values.customBalancer.log.level "DEBUG" }}
       print(string.format("DEBUG: ENDPOINT %s wasn't find in balancer talbes, re-set endpoint for shardkey %s", exist_endpoint, API_KEY))
       {{- end }}
       reset_custom_endpoint(API_KEY)
     else
       {{- if eq .Values.customBalancer.log.level "DEBUG" }}
       print(string.format("DEGUB: ENDPOINT %s exist in RESERVED table, just go forward...", exist_endpoint))
       {{- end }}
       ngx.var.custom_endpoint = exist_endpoint
     end
   else
     {{- if eq .Values.customBalancer.log.level "DEBUG" }}
     print(string.format("DEGUB: ENDPOINT %s exist in LIVE table, just go forward...", exist_endpoint))
     {{- end }}
     ngx.var.custom_endpoint = exist_endpoint
   end
 end
{{- if and .Values.connections.redisKeepaliveTimeout .Values.connections.redisKeepalivePoolSize }}
local ok, err = red:set_keepalive({{ .Values.connections.redisKeepaliveTimeout }}, {{ .Values.connections.redisKeepalivePoolSize }})
if not ok then
  {{- if eq .Values.customBalancer.log.level "DEBUG" }}
  print("DEBUG: Redis keepalive error when return connection to pool")
  {{- end }}
  ngx.say("failed to set keepalive: ", err)
end
{{- else }}
{{- if not .Values.connections.redisClusterNodes }}
red:close()
{{- end }}
{{- if eq .Values.customBalancer.log.level "DEBUG" }}
print(string.format("DEBUG: SHARDKEY: %s, ENDPOINT: %s", API_KEY, ngx.var.custom_endpoint))
{{- end }}
{{- end }}
end

}

set $docs_shardkey $arg_shardkey;
set $docs_wopisrc $arg_WOPISrc;

if ($docs_shardkey) {
   proxy_pass http://$custom_endpoint;
}

if ($docs_wopisrc) {
   proxy_pass http://$custom_endpoint;
}
